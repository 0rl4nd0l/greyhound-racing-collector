"""
Enhanced Pipeline V2
====================

Integrates the advanced feature engineering v2, advanced ML system v2, 
and data quality improver into a single enhanced prediction pipeline.
"""

import logging
import pandas as pd
import numpy as np
import os
import json
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)

# Try to import components, handle gracefully if missing
try:
    from enhanced_feature_engineering_v2 import AdvancedFeatureEngineer
    FEATURE_ENGINEER_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Enhanced feature engineering not available: {e}")
    FEATURE_ENGINEER_AVAILABLE = False

try:
    from advanced_ml_system_v2 import AdvancedMLSystemV2
    ML_SYSTEM_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Advanced ML system not available: {e}")
    ML_SYSTEM_AVAILABLE = False

try:
    from data_quality_improver import DataQualityImprover
    DATA_IMPROVER_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Data quality improver not available: {e}")
    DATA_IMPROVER_AVAILABLE = False

class EnhancedPipelineV2:
    def __init__(self, db_path="greyhound_racing_data.db"):
        self.db_path = db_path
        
        # Initialize components if available
        self.feature_engineer = None
        self.ml_system = None
        self.data_improver = None
        
        if FEATURE_ENGINEER_AVAILABLE:
            try:
                self.feature_engineer = AdvancedFeatureEngineer(db_path)
                logger.info("âœ… Advanced Feature Engineer initialized")
            except Exception as e:
                logger.warning(f"Feature engineer initialization failed: {e}")
        
        if ML_SYSTEM_AVAILABLE:
            try:
                self.ml_system = AdvancedMLSystemV2()
                logger.info("âœ… Advanced ML System V2 initialized")
            except Exception as e:
                logger.warning(f"ML system initialization failed: {e}")
        
        if DATA_IMPROVER_AVAILABLE:
            try:
                self.data_improver = DataQualityImprover(db_path)
                logger.info("âœ… Data Quality Improver initialized")
            except Exception as e:
                logger.warning(f"Data improver initialization failed: {e}")
    
    def predict_race_file(self, race_file_path: str) -> dict:
        """Main prediction method for race file"""
        try:
            logger.info(f"ðŸš€ Enhanced Pipeline V2 processing: {os.path.basename(race_file_path)}")
            
            # Step 1: Load race file and basic processing
            race_df = self._load_race_file(race_file_path)
            if race_df is None or race_df.empty:
                return self._error_response("Could not load race file or file is empty")
            
            # Step 2: Extract participating dogs
            participating_dogs = self._extract_participating_dogs(race_df)
            if not participating_dogs:
                return self._error_response("No participating dogs found in race file")
            
            logger.info(f"ðŸ“Š Found {len(participating_dogs)} participating dogs")
            
            # Step 3: Enhanced prediction pipeline
            predictions = []
            
            for dog_info in participating_dogs:
                dog_name = dog_info['name']
                box_number = dog_info.get('box', 0)
                
                # Generate enhanced features if components available
                enhanced_features = self._generate_enhanced_features(
                    dog_name, race_file_path, dog_info
                )
                
                # Generate prediction score using ML system if available
                prediction_score = self._generate_prediction_score(
                    enhanced_features, dog_name
                )
                
                # Calculate confidence
                confidence_level, confidence_score = self._calculate_confidence(
                    prediction_score, enhanced_features
                )
                
                prediction = {
                    'dog_name': dog_name,
                    'clean_name': dog_name,  # For compatibility
                    'box_number': box_number,
                    'prediction_score': round(prediction_score, 3),
                    'confidence_level': confidence_level,
                    'confidence_score': round(confidence_score, 3),
                    'enhanced_features_used': len(enhanced_features) > 0,
                    'prediction_method': 'enhanced_pipeline_v2',
                    'reasoning': self._generate_reasoning(
                        prediction_score, enhanced_features, dog_name
                    )
                }
                
                predictions.append(prediction)
            
            # Sort by prediction score
            predictions.sort(key=lambda x: x['prediction_score'], reverse=True)
            
            # Add ranking
            for i, pred in enumerate(predictions, 1):
                pred['rank'] = i
            
            # Prepare response
            return {
                'success': True,
                'predictions': predictions,
                'race_info': {
                    'filename': os.path.basename(race_file_path),
                    'total_dogs': len(predictions),
                    'venue': self._extract_venue_from_filename(race_file_path),
                    'race_date': self._extract_date_from_filename(race_file_path)
                },
                'prediction_method': 'enhanced_pipeline_v2',
                'enhanced_components_used': {
                    'feature_engineering': self.feature_engineer is not None,
                    'ml_system': self.ml_system is not None,
                    'data_improver': self.data_improver is not None
                },
                'analysis_timestamp': datetime.now().isoformat(),
                'top_pick': predictions[0] if predictions else None
            }
            
        except Exception as e:
            logger.error(f"Enhanced Pipeline V2 error: {str(e)}")
            return self._error_response(f"Pipeline error: {str(e)}")
    
    def _load_race_file(self, race_file_path: str) -> pd.DataFrame:
        """Load and parse race file"""
        try:
            # Auto-detect delimiter
            with open(race_file_path, 'r', encoding='utf-8') as f:
                first_line = f.readline()
                delimiter = '|' if '|' in first_line else ','
            
            df = pd.read_csv(race_file_path, delimiter=delimiter)
            return df
        except Exception as e:
            logger.error(f"Error loading race file: {e}")
            return None
    
    def _extract_participating_dogs(self, race_df: pd.DataFrame) -> list:
        """Extract participating dogs from race data with embedded historical data"""
        dogs = []
        current_dog_history = []
        current_dog_name = None
        current_box_number = None
        
        try:
            for idx, row in race_df.iterrows():
                dog_name_raw = str(row.get('Dog Name', '')).strip()
                
                # Check if this is a new dog (has a name) or historical data (nan/empty)
                if dog_name_raw and dog_name_raw not in ['""', '', 'nan', 'NaN']:
                    # Save previous dog if we have one
                    if current_dog_name and current_dog_history:
                        dogs.append({
                            'name': current_dog_name,
                            'box': current_box_number or len(dogs) + 1,
                            'historical_data': current_dog_history.copy(),
                            'raw_data': current_dog_history[0] if current_dog_history else {}
                        })
                    
                    # Start new dog
                    current_dog_name = dog_name_raw
                    current_box_number = None
                    current_dog_history = []
                    
                    # Extract box number from name if present
                    if '. ' in current_dog_name:
                        parts = current_dog_name.split('. ', 1)
                        if len(parts) == 2:
                            try:
                                current_box_number = int(parts[0])
                                current_dog_name = parts[1]
                            except ValueError:
                                pass
                    
                    # Add this row to history
                    current_dog_history.append(row.to_dict())
                
                elif current_dog_name:  # This is historical data for current dog
                    current_dog_history.append(row.to_dict())
            
            # Don't forget the last dog
            if current_dog_name and current_dog_history:
                dogs.append({
                    'name': current_dog_name,
                    'box': current_box_number or len(dogs) + 1,
                    'historical_data': current_dog_history.copy(),
                    'raw_data': current_dog_history[0] if current_dog_history else {}
                })
        
        except Exception as e:
            logger.error(f"Error extracting dogs: {e}")
        
        return dogs
    
    def _generate_enhanced_features(self, dog_name: str, race_file_path: str, dog_info: dict) -> dict:
        """Generate enhanced features using available components and embedded historical data"""
        features = {}
        
        # Base features from race file data
        features['box_number'] = dog_info.get('box', 0)
        features['has_recent_form'] = 0.5  # Default
        
        # Extract features from embedded historical data first
        embedded_features = self._extract_features_from_historical_data(dog_info, race_file_path)
        features.update(embedded_features)
        
        # Use feature engineer if available for additional features
        if self.feature_engineer:
            try:
                # Load comprehensive data
                comprehensive_data = self.feature_engineer.load_comprehensive_data()
                
                # Extract venue from filename
                venue = self._extract_venue_from_filename(race_file_path)
                race_date = self._extract_date_from_filename(race_file_path)
                
                # Generate advanced features (this may override some embedded features)
                advanced_features = self.feature_engineer.create_advanced_dog_features(
                    comprehensive_data, dog_name, race_date, venue
                )
                
                # Merge advanced features, but prioritize embedded data where available
                for key, value in advanced_features.items():
                    if key not in features or features[key] == 0 or features[key] == 5.0:  # Default values
                        features[key] = value
                
                logger.debug(f"Generated {len(advanced_features)} advanced features for {dog_name}")
                
            except Exception as e:
                logger.warning(f"Error generating enhanced features for {dog_name}: {e}")
        
        # Use data improver if available
        if self.data_improver:
            try:
                # Add data quality metrics
                data_quality = self.data_improver.calculate_data_quality_score(features)
                features['data_quality'] = data_quality
            except Exception as e:
                logger.warning(f"Error calculating data quality: {e}")
                features['data_quality'] = 0.5
        else:
            features['data_quality'] = 0.7 if len(embedded_features) > 5 else 0.5  # Higher quality if we have embedded data
        
        return features
    
    def _generate_prediction_score(self, features: dict, dog_name: str) -> float:
        """Generate prediction score using ML system if available"""
        if self.ml_system and features:
            try:
                # Use ensemble prediction if models are trained
                if hasattr(self.ml_system, 'models') and self.ml_system.models:
                    score = self.ml_system.predict_with_ensemble(features)
                    logger.debug(f"ML ensemble score for {dog_name}: {score:.3f}")
                    return score
            except Exception as e:
                logger.warning(f"Error generating ML prediction for {dog_name}: {e}")
        
        # Fallback: heuristic-based scoring
        return self._generate_heuristic_score(features, dog_name)
    
    def _generate_heuristic_score(self, features: dict, dog_name: str) -> float:
        """Generate heuristic-based prediction score with enhanced differentiation"""
        base_score = 0.5
        
        # Enhanced box position influence with more granular effects
        box_number = features.get('box_number', 0)
        box_adjustments = {
            1: 0.08,   # Rail position advantage
            2: 0.06,   # Good early position
            3: 0.04,   # Decent position
            4: 0.02,   # Slightly favorable
            5: -0.01,  # Starting to be wide
            6: -0.03,  # Wide barrier
            7: -0.05,  # Very wide
            8: -0.07   # Extreme wide barrier
        }
        base_score += box_adjustments.get(box_number, 0)
        
        # Enhanced features influence
        if 'weighted_recent_form' in features:
            form_score = features['weighted_recent_form']
            if form_score < 3.0:  # Excellent recent form
                base_score += 0.15
            elif form_score < 4.0:  # Good recent form
                base_score += 0.08
            elif form_score > 6.0:  # Poor recent form
                base_score -= 0.12
            elif form_score > 5.0:  # Below average form
                base_score -= 0.06
        
        if 'venue_win_rate' in features:
            venue_rate = features['venue_win_rate']
            base_score += venue_rate * 0.20  # Increase venue impact
        
        if 'speed_trend' in features:
            speed_trend = features['speed_trend']
            if speed_trend < -0.2:  # Significantly improving
                base_score += 0.10
            elif speed_trend < 0:  # Improving times
                base_score += 0.05
            elif speed_trend > 0.2:  # Declining form
                base_score -= 0.08
        
        # Additional differentiating factors when historical data is limited
        if features.get('weighted_recent_form', 0) == 5.0:  # Default value indicates limited data
            # Use dog name characteristics for differentiation (consistent but varied)
            name_hash = hash(dog_name) % 1000
            name_factor = (name_hash / 1000 - 0.5) * 0.15  # Range: -0.075 to +0.075
            base_score += name_factor
            
            # Add box-based premium for limited data scenarios
            if box_number <= 3:
                base_score += 0.03  # Extra boost for inside boxes when data is limited
        
        # Class and experience factors
        if 'grade_trend' in features:
            grade_trend = features['grade_trend']
            if grade_trend < -0.5:  # Moving up in class successfully
                base_score += 0.06
            elif grade_trend > 0.5:  # Struggling in higher class
                base_score -= 0.04
        
        if 'venue_experience' in features:
            venue_exp = features['venue_experience']
            if venue_exp > 5:  # Experienced at venue
                base_score += 0.04
            elif venue_exp == 0:  # First time at venue
                base_score -= 0.02
        
        # Data quality adjustment
        data_quality = features.get('data_quality', 0.5)
        base_score *= (0.85 + 0.30 * data_quality)
        
        # Controlled randomness with seed based on dog name for consistency
        import random
        random.seed(hash(dog_name) % 2147483647)  # Consistent seed per dog
        base_score += random.uniform(-0.08, 0.08)
        random.seed()  # Reset to random seed
        
        return max(0.05, min(0.95, base_score))
    
    def _calculate_confidence(self, prediction_score: float, features: dict) -> tuple:
        """Calculate confidence level and score"""
        # Base confidence from ML system if available and has models
        if (self.ml_system and hasattr(self.ml_system, 'generate_prediction_confidence') 
            and hasattr(self.ml_system, 'models') and self.ml_system.models):
            try:
                confidence_score = self.ml_system.generate_prediction_confidence(features)
            except Exception:
                confidence_score = 0.6
        else:
            # Heuristic confidence calculation
            data_quality = features.get('data_quality', 0.5)
            feature_count = len([k for k, v in features.items() 
                               if k not in ['box_number', 'data_quality'] and v != 0])
            
            confidence_score = min(0.9, 0.4 + (data_quality * 0.3) + (feature_count * 0.02))
        
        # Convert to level
        if confidence_score >= 0.7:
            confidence_level = 'HIGH'
        elif confidence_score >= 0.5:
            confidence_level = 'MEDIUM'
        else:
            confidence_level = 'LOW'
        
        return confidence_level, confidence_score
    
    def _generate_reasoning(self, prediction_score: float, features: dict, dog_name: str) -> str:
        """Generate human-readable reasoning for prediction"""
        reasons = []
        
        if prediction_score > 0.65:
            reasons.append("Strong prediction based on")
        elif prediction_score > 0.45:
            reasons.append("Moderate prediction based on")
        else:
            reasons.append("Weak prediction based on")
        
        # Add feature-based reasons
        if 'weighted_recent_form' in features:
            form = features['weighted_recent_form']
            if form < 3.0:
                reasons.append("excellent recent form")
            elif form < 4.5:
                reasons.append("good recent form")
        
        if 'venue_win_rate' in features and features['venue_win_rate'] > 0.3:
            reasons.append("strong venue performance")
        
        if 'speed_trend' in features and features['speed_trend'] < -0.1:
            reasons.append("improving speed trend")
        
        box_number = features.get('box_number', 0)
        if box_number in [1, 2, 3]:
            reasons.append("favorable box position")
        
        if len(reasons) == 1:
            reasons.append("limited historical data")
        
        return " ".join(reasons) + "."
    
    def _extract_venue_from_filename(self, filename: str) -> str:
        """Extract venue from filename"""
        try:
            basename = os.path.basename(filename)
            # Try different patterns
            if ' - ' in basename:
                parts = basename.split(' - ')
                if len(parts) >= 2:
                    return parts[1]
            elif '_' in basename:
                parts = basename.split('_')
                if len(parts) >= 2:
                    return parts[1]
            return "UNKNOWN"
        except Exception:
            return "UNKNOWN"
    
    def _extract_date_from_filename(self, filename: str) -> str:
        """Extract date from filename"""
        try:
            basename = os.path.basename(filename)
            # Look for date pattern YYYY-MM-DD
            import re
            date_pattern = r'(\d{4}-\d{2}-\d{2})'
            match = re.search(date_pattern, basename)
            if match:
                return match.group(1)
            return datetime.now().strftime('%Y-%m-%d')
        except Exception:
            return datetime.now().strftime('%Y-%m-%d')
    
    def _extract_features_from_historical_data(self, dog_info: dict, race_file_path: str) -> dict:
        """Extract meaningful features from embedded historical race data in CSV"""
        features = {}
        
        try:
            historical_data = dog_info.get('historical_data', [])
            if not historical_data:
                return features
            
            # Convert to DataFrame for easier processing
            df = pd.DataFrame(historical_data)
            
            # Clean and convert data types
            df['PLC'] = pd.to_numeric(df['PLC'], errors='coerce')
            df['TIME'] = pd.to_numeric(df['TIME'], errors='coerce')
            df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
            df['BOX'] = pd.to_numeric(df['BOX'], errors='coerce')
            df['DIST'] = pd.to_numeric(df['DIST'], errors='coerce')
            df['SP'] = pd.to_numeric(df['SP'], errors='coerce')
            
            # Remove rows with missing critical data
            df = df.dropna(subset=['PLC', 'TIME', 'DATE'])
            
            if len(df) == 0:
                return features
            
            # Sort by date (most recent first)
            df = df.sort_values('DATE', ascending=False)
            
            # 1. Weighted Recent Form (last 5 races)
            recent_positions = df['PLC'].head(5).tolist()
            if recent_positions:
                weights = [0.4, 0.3, 0.2, 0.1, 0.05][:len(recent_positions)]
                features['weighted_recent_form'] = sum(pos * weight for pos, weight in zip(recent_positions, weights))
            
            # 2. Speed Trend Analysis
            recent_times = df['TIME'].head(5).dropna()
            if len(recent_times) >= 3:
                # Calculate trend (negative = improving times)
                features['speed_trend'] = np.polyfit(range(len(recent_times)), recent_times, 1)[0]
                features['speed_consistency'] = recent_times.std()
            else:
                features['speed_trend'] = 0
                features['speed_consistency'] = 0
            
            # 3. Venue-specific Performance
            venue = self._extract_venue_from_filename(race_file_path)
            venue_data = df[df['TRACK'].str.contains(venue[:4], case=False, na=False)] if venue != "UNKNOWN" else df
            
            if len(venue_data) > 0:
                features['venue_win_rate'] = (venue_data['PLC'] == 1).mean()
                features['venue_avg_position'] = venue_data['PLC'].mean()
                features['venue_experience'] = len(venue_data)
            else:
                features['venue_win_rate'] = 0
                features['venue_avg_position'] = 5.0
                features['venue_experience'] = 0
            
            # 4. Distance-specific Performance
            race_distance = 516  # Default distance, could be extracted from race info
            distance_data = df[df['DIST'] == race_distance]
            if len(distance_data) > 0:
                features['distance_win_rate'] = (distance_data['PLC'] == 1).mean()
                features['distance_avg_time'] = distance_data['TIME'].mean()
            else:
                features['distance_win_rate'] = features.get('venue_win_rate', 0)
                features['distance_avg_time'] = df['TIME'].mean() if len(df) > 0 else 30.0
            
            # 5. Box Position Analysis
            current_box = dog_info.get('box', 0)
            similar_box_data = df[df['BOX'] == current_box]
            if len(similar_box_data) > 0:
                features['box_position_win_rate'] = (similar_box_data['PLC'] == 1).mean()
                features['box_position_avg'] = similar_box_data['PLC'].mean()
            else:
                # Use general box performance
                features['box_position_win_rate'] = 0.1  # Default
                features['box_position_avg'] = 5.0
            
            # 6. Recent Performance Momentum
            if len(df) >= 3:
                last_3_races = df['PLC'].head(3).tolist()
                if all(pos <= 3 for pos in last_3_races):  # Consistent top 3
                    features['recent_momentum'] = 0.8
                elif all(pos <= 2 for pos in last_3_races[:2]):  # Recent wins/places
                    features['recent_momentum'] = 0.6
                else:
                    features['recent_momentum'] = 0.3
            else:
                features['recent_momentum'] = 0.5
            
            # 7. Competitive Level (based on starting prices)
            if 'SP' in df.columns and not df['SP'].isna().all():
                avg_sp = df['SP'].mean()
                if avg_sp < 5.0:  # Often favored
                    features['competitive_level'] = 0.8
                elif avg_sp < 15.0:  # Sometimes favored
                    features['competitive_level'] = 0.6
                else:  # Long shots
                    features['competitive_level'] = 0.4
            else:
                features['competitive_level'] = 0.5
            
            # 8. Consistency Metrics
            if len(df) >= 5:
                positions = df['PLC'].head(10)
                features['position_consistency'] = 1.0 / (1.0 + positions.std())  # Lower std = higher consistency
                features['top_3_rate'] = (positions <= 3).mean()
            else:
                features['position_consistency'] = 0.5
                features['top_3_rate'] = 0.3
            
            # 9. Break Patterns (first vs second sectional)
            # This would need more detailed sectional data, using simplified version
            features['break_quality'] = 0.5  # Placeholder
            
            logger.debug(f"Extracted {len(features)} features from {len(df)} historical races")
            
        except Exception as e:
            logger.warning(f"Error extracting features from historical data: {e}")
        
        return features
    
    def _error_response(self, error_message: str) -> dict:
        """Generate error response"""
        return {
            'success': False,
            'error': error_message,
            'predictions': [],
            'prediction_method': 'enhanced_pipeline_v2'
        }
