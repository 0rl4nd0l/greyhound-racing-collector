#!/usr/bin/env python3
"""
Direct Model Trainer
====================

Trains ML models directly from database data and saves the best performing 
model to the registry for immediate use by the prediction system.

This leverages the successful ML backtesting approach but focuses on 
direct model registration and deployment.
"""

import os
import numpy as np
import pandas as pd
from datetime import datetime
from ml_backtesting_trainer import MLBacktestingTrainer
from model_registry import get_model_registry
from sklearn.metrics import f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
import joblib

def train_and_register_best_model():
    """Train models and register the best one in the registry"""
    print("ğŸš€ Direct Model Training and Registration")
    print("=" * 60)
    
    # Initialize trainer
    trainer = MLBacktestingTrainer()
    
    # Load and prepare data
    print("ğŸ“Š Loading historical data...")
    historical_df = trainer.load_historical_race_data(months_back=6)
    if historical_df is None or len(historical_df) < 100:
        print("âŒ Insufficient historical data")
        return None
    
    print("ğŸ”§ Creating enhanced features...")
    enhanced_df = trainer.create_enhanced_features(historical_df)
    if len(enhanced_df) < 50:
        print("âŒ Insufficient enhanced data")
        return None
    
    print("âš™ï¸ Preparing ML dataset...")
    ml_df, feature_columns = trainer.prepare_ml_dataset(enhanced_df)
    
    # Train the best win prediction model
    print("ğŸ¯ Training optimized model...")
    best_model_info = trainer.optimize_best_model(ml_df, feature_columns, 'is_winner')
    
    if not best_model_info:
        print("âŒ Model training failed")
        return None
    
    # Extract model components
    model = best_model_info['model']
    scaler = best_model_info['scaler']
    model_name = best_model_info['model_name']
    test_accuracy = best_model_info['test_accuracy']
    
    # Prepare data for additional metrics calculation
    df_sorted = ml_df.sort_values('race_date')
    split_point = int(0.8 * len(df_sorted))
    train_df = df_sorted.iloc[:split_point]
    test_df = df_sorted.iloc[split_point:]
    
    X_train = train_df[feature_columns]
    y_train = train_df['is_winner']
    X_test = test_df[feature_columns]
    y_test = test_df['is_winner']
    
    # Scale test data
    X_test_scaled = scaler.transform(X_test)
    
    # Make predictions for comprehensive metrics
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    
    # Calculate comprehensive metrics
    f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)
    precision = precision_score(y_test, y_pred, average='binary', zero_division=0)
    recall = recall_score(y_test, y_pred, average='binary', zero_division=0)
    
    # AUC calculation
    from sklearn.metrics import roc_auc_score
    try:
        auc = roc_auc_score(y_test, y_pred_proba)
    except:
        auc = 0.5
    
    print(f"\nğŸ“Š Model Performance Metrics:")
    print(f"   ğŸ¯ Test Accuracy: {test_accuracy:.3f}")
    print(f"   ğŸ“ˆ AUC Score: {auc:.3f}")
    print(f"   ğŸ† F1 Score: {f1:.3f}")
    print(f"   ğŸª Precision: {precision:.3f}")
    print(f"   ğŸ“ Recall: {recall:.3f}")
    
    # Register model in registry
    try:
        registry = get_model_registry()
        
        # Prepare performance metrics
        performance_metrics = {
            'accuracy': test_accuracy,
            'auc': auc,
            'f1_score': f1,
            'precision': precision,
            'recall': recall
        }
        
        # Prepare training info
        training_info = {
            'training_samples': len(X_train),
            'test_samples': len(X_test),
            'training_duration': 0.0,
            'validation_method': 'time_series_split',
            'cv_scores': [],
            'is_ensemble': False,
            'ensemble_components': [],
            'data_quality_score': 0.85,  # High quality from database
            'inference_time_ms': 5.0
        }
        
        # Generate model notes
        notes = f"Direct trained {model_name} from {len(X_train)} database samples. Optimized via grid search with time-series validation."
        
        # Register the model
        model_id = registry.register_model(
            model_obj=model,
            scaler_obj=scaler,
            model_name=model_name,
            model_type='database_trained',
            performance_metrics=performance_metrics,
            training_info=training_info,
            feature_names=feature_columns,
            hyperparameters=best_model_info.get('params', {}),
            notes=notes
        )
        
        print(f"\nâœ… Model successfully registered!")
        print(f"   ğŸ†” Model ID: {model_id}")
        print(f"   ğŸ“Š Performance: Acc={test_accuracy:.3f}, AUC={auc:.3f}, F1={f1:.3f}")
        print(f"   ğŸ·ï¸ Model Type: {model_name}")
        print(f"   ğŸ“ Features: {len(feature_columns)}")
        
        # Also save legacy format for compatibility
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        legacy_path = f"comprehensive_trained_models/direct_trained_{timestamp}.joblib"
        
        os.makedirs("comprehensive_trained_models", exist_ok=True)
        
        legacy_data = {
            'model': model,
            'model_name': model_name,
            'accuracy': test_accuracy,
            'auc': auc,
            'feature_columns': feature_columns,
            'scaler': scaler,
            'timestamp': timestamp,
            'training_samples': len(X_train),
            'registry_id': model_id
        }
        
        joblib.dump(legacy_data, legacy_path)
        print(f"   ğŸ“ Legacy backup: {legacy_path}")
        
        return {
            'model_id': model_id,
            'model': model,
            'scaler': scaler,
            'accuracy': test_accuracy,
            'auc': auc,
            'f1_score': f1
        }
        
    except Exception as e:
        print(f"âŒ Error registering model: {e}")
        return None

def test_trained_model():
    """Test the newly trained model"""
    print("\nğŸ§ª Testing newly trained model...")
    
    try:
        from enhanced_pipeline_v2 import EnhancedPipelineV2
        
        pipeline = EnhancedPipelineV2()
        
        # Find a test race file
        test_files = [f for f in os.listdir('upcoming_races') if f.endswith('.csv')]
        if not test_files:
            print("âŒ No test files available")
            return
        
        test_file = f'upcoming_races/{test_files[0]}'
        print(f"   Testing with: {test_files[0]}")
        
        result = pipeline.predict_race_file(test_file)
        
        if result['success']:
            predictions = result['predictions']
            scores = [pred['prediction_score'] for pred in predictions]
            
            print(f"   ğŸ“Š Score range: {min(scores):.3f} - {max(scores):.3f}")
            print(f"   ğŸ“ˆ Score variance: {np.var(scores):.6f}")
            print(f"   ğŸ Dogs predicted: {len(predictions)}")
            
            print("\n   ğŸ† Top 3 predictions:")
            for i, pred in enumerate(predictions[:3], 1):
                confidence = pred.get('confidence_level', 'MEDIUM')
                print(f"      {i}. {pred['dog_name']:15}: {pred['prediction_score']:.3f} ({confidence})")
            
            if np.var(scores) > 0.001:
                print("   âœ… Model shows good score differentiation!")
            else:
                print("   âš ï¸ Model shows limited score differentiation")
                
        else:
            print(f"   âŒ Test failed: {result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"   âŒ Test error: {e}")

def main():
    """Main training and registration process"""
    print("ğŸ¯ Direct Model Training System")
    print("=" * 40)
    
    # Train and register the model
    result = train_and_register_best_model()
    
    if result:
        print(f"\nğŸ‰ Training completed successfully!")
        print(f"   Model ID: {result['model_id']}")
        print(f"   Performance: {result['accuracy']:.3f} accuracy, {result['auc']:.3f} AUC")
        
        # Test the model
        test_trained_model()
        
        print(f"\nğŸ”„ The prediction system will automatically use the new model.")
        print(f"   You can now run predictions and they will use the freshly trained model!")
        
    else:
        print(f"\nâŒ Training failed. Please check the data and try again.")

if __name__ == "__main__":
    main()
